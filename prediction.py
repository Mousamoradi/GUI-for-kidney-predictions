# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'dialog5.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QFileDialog
from PyQt5.QtGui import QImage
import matplotlib
from datetime import datetime
import os
import sys
matplotlib.use("Qt5Agg")
import cv2, imutils
from PIL import Image
import tensorflow as tf
from tensorflow.keras import models, layers, regularizers
from tensorflow.keras import backend as K
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib.ticker as ticker
from matplotlib.figure import Figure
from matplotlib.backends.backend_qt5agg import (FigureCanvas, NavigationToolbar2QT as NavigationToolbar)
from tensorflow.keras.optimizers import Adam
from patchify import patchify, unpatchify
from tensorflow.keras.models import Model,load_model
from tensorflow.keras import optimizers
from skimage.morphology import label
from collections import defaultdict
from sklearn import preprocessing
from scipy.interpolate import interp1d
import win32api


class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(733, 851)
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.gridLayout = QtWidgets.QGridLayout(self.centralwidget)
        self.gridLayout.setObjectName("gridLayout")
        self.label = QtWidgets.QLabel(self.centralwidget)
        font = QtGui.QFont()
        font.setPointSize(16)
        self.label.setFont(font)
        self.label.setObjectName("label")
        self.gridLayout.addWidget(self.label, 0, 0, 1, 2)
        spacerItem = QtWidgets.QSpacerItem(67, 28, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum)
        self.gridLayout.addItem(spacerItem, 0, 4, 1, 1)
        self.pushButton = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton.setObjectName("pushButton")
        self.gridLayout.addWidget(self.pushButton, 1, 0, 1, 1)
        spacerItem1 = QtWidgets.QSpacerItem(40, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum)
        self.gridLayout.addItem(spacerItem1, 1, 1, 2, 2)
        self.label_3 = QtWidgets.QLabel(self.centralwidget)
        font = QtGui.QFont()
        font.setPointSize(10)
        font.setBold(True)
        font.setWeight(75)
        self.label_3.setFont(font)
        self.label_3.setObjectName("label_3")
        self.gridLayout.addWidget(self.label_3, 1, 3, 1, 1)
        self.pushButton_2 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_2.setObjectName("pushButton_2")
        self.gridLayout.addWidget(self.pushButton_2, 2, 0, 1, 1)
        self.label_4 = QtWidgets.QLabel(self.centralwidget)
        font = QtGui.QFont()
        font.setPointSize(10)
        font.setBold(True)
        font.setWeight(75)
        self.label_4.setFont(font)
        self.label_4.setObjectName("label_4")
        self.gridLayout.addWidget(self.label_4, 2, 3, 1, 1)
        self.widget = QtWidgets.QWidget(self.centralwidget)
        self.widget.setObjectName("widget")
        self.gridLayout.addWidget(self.widget, 3, 0, 2, 4)
        self.verticalSlider = QtWidgets.QSlider(self.centralwidget)
        self.verticalSlider.setOrientation(QtCore.Qt.Vertical)
        self.verticalSlider.setObjectName("verticalSlider")
        self.gridLayout.addWidget(self.verticalSlider, 3, 4, 1, 1)
        spacerItem2 = QtWidgets.QSpacerItem(660, 17, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum)
        self.gridLayout.addItem(spacerItem2, 4, 1, 1, 1)
        self.widget_2 = QtWidgets.QWidget(self.centralwidget)
        self.widget_2.setObjectName("widget_2")
        #add horizontal layout
        self.plotLayout_1=QtWidgets.QGridLayout(self.widget)
        self.plotLayout_1.setObjectName("plotLayout_1")
        self.plotLayout_2=QtWidgets.QGridLayout(self.widget_2)
        self.plotLayout_2.setObjectName("plotLayout_2")
        #Canvas here
        self.canvas1 = FigureCanvas(Figure(tight_layout=True))
        self.canvas2 = FigureCanvas(Figure(tight_layout=True))
        self.plotLayout_1.addWidget(self.canvas1)
        self.plotLayout_2.addWidget(self.canvas2)   
        self.canvas1.ax1 = self.canvas1.figure.add_subplot(211)
        self.canvas1.ax2 = self.canvas1.figure.add_subplot(212)
        self.canvas2.ax1 = self.canvas2.figure.add_subplot(211)
        self.canvas2.ax2 = self.canvas2.figure.add_subplot(212)
        #end canvas
        self.gridLayout.addWidget(self.widget_2, 5, 0, 1, 4)
        spacerItem3 = QtWidgets.QSpacerItem(58, 318, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding)
        self.gridLayout.addItem(spacerItem3, 5, 4, 1, 1)
        spacerItem4 = QtWidgets.QSpacerItem(660, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum)
        self.gridLayout.addItem(spacerItem4, 6, 2, 1, 2)
        self.checkBox = QtWidgets.QCheckBox(self.centralwidget)
        self.checkBox.setObjectName("checkBox")
        self.gridLayout.addWidget(self.checkBox, 4, 4, 1, 1)
        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 733, 21))
        self.menubar.setObjectName("menubar")
        self.menuMenu = QtWidgets.QMenu(self.menubar)
        self.menuMenu.setObjectName("menuMenu")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)
        self.actionSave_images = QtWidgets.QAction(MainWindow)
        self.actionSave_images.setObjectName("actionSave_images")
        self.actionSave_plots = QtWidgets.QAction(MainWindow)
        self.actionSave_plots.setObjectName("actionSave_plots")
        self.menuMenu.addAction(self.actionSave_images)
        self.menuMenu.addAction(self.actionSave_plots)
        self.menubar.addAction(self.menuMenu.menuAction())
        self.checkBox.stateChanged.connect(lambda: self.checked())
        

        self.retranslateUi(MainWindow)
        self.verticalSlider.valueChanged['int'].connect(self.clahe_value)
        self.pushButton.clicked.connect(self.loadImage)
        self.pushButton_2.clicked.connect(self.loadModel)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)
       
       
        self.filename = None # Will hold the image address location
        self.fname = None
        self.tmp = None # Will hold the temporary image for display
        self.clahe_value_now = 0 # Updated brightness value
        
    def loadImage(self):
        self.filename = QFileDialog.getOpenFileName(filter="Image (*.*)")[0]
        self.image = cv2.imread(self.filename)
        self.setPhoto(self.image)
    def setPhoto(self,image):
        #self.figure.clf()
        self.tmp = image
        #image = cv2.resize(image, (2048,512))
        #self.scl=3.85*3.85/image.shape[0]*image.shape[0]/image.shape[1]*image.shape[1]
        self.scl=5/image.shape[1]*1000
        self.canvas1.ax1.imshow(image,cmap='gray')
        self.canvas1.ax1.set_title('Pixel Resulution: {:.3f}  um/pixel'.format(self.scl))
        plt.tight_layout()
        self.canvas1.draw()
       
    def clahe_value(self,value):
        """ This function will take value from the slider 
        for the kernel size from 0 to 99 """
        self.clahe_value_now = value
        print('Kernel Size: ',value)
        self.update()
        
    def changeCLAHE(self,img,value):
        kernelsize = (value+1,value+1) # +1 is to avoid 0
        clahe = cv2.createCLAHE(clipLimit=1.5,tileGridSize=kernelsize)
        grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        equ=clahe.apply(grayimg)
        self.img = cv2.cvtColor(equ,cv2.COLOR_BGR2RGB)
        return self.img    
    
    def update(self):
        img = self.changeCLAHE(self.image,self.clahe_value_now)
        self.setPhoto(img)
        
    def loadModel(self):
        self.canvas2.ax1.clear()
        self.canvas2.ax2.clear()
        self.fname = QFileDialog.getOpenFileName(filter="Select A Model (*.HDF5)")[0]
        input_shape=(256,256,1)
        att_res_unet_model = Attention_ResUNet(input_shape)
        att_res_unet_model.compile(optimizer=Adam(learning_rate = 0.0001), loss=dice_coef_loss, 
        metrics=["binary_accuracy", iou, dice_coef, tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])
        model=att_res_unet_model
        
        model.load_weights(self.fname)
        
        patch_size = 256
        SIZE_X = (self.img.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size
        SIZE_Y = (self.img.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size
               
        image = Image.fromarray(self.img)
        image = image.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner
        image = np.array(image)  
 
        image1 = image[:,:,0]
        patches = patchify(image, (256, 256,3), step=256)  #Step=256 for 256 patches means no overlap
        print(patches.shape)
        predicted_patches = []
        for i in range(patches.shape[0]):
            for j in range(patches.shape[1]):
                print(i,j)
                single_patch = patches[i,j,0,:,:,0]
                image = Image.fromarray(single_patch)
                image=np.array(image)
                img=np.expand_dims(image,2)
                img = img / 255
                img = img[np.newaxis, :, :, :]
                pred= model.predict(img)
                pre=np.squeeze(pred) > .5
                pre=np.uint8(pre)
                predicted_patches.append(pre)
        self.predicted_patches = np.array(predicted_patches)
        predicted_patches_reshaped = np.reshape(self.predicted_patches, (patches.shape[0], patches.shape[1], 256,256))
        self.reconstructed_image = unpatchify(predicted_patches_reshaped, image1.shape)
        self.setPred(self.reconstructed_image)
        self.plotdendia(self.predicted_patches)
    def setPred(self,reconstructed_image):
        self.canvas1.ax2.clear()
        image1 = self.img[:,:,0]
        reconstructed_image = cv2.resize(reconstructed_image, (self.img.shape[1],self.img.shape[0]))
        prer=np.uint8(reconstructed_image)
        prer=cv2.cvtColor(prer,cv2.COLOR_GRAY2RGB)
        image2=cv2.cvtColor(image1,cv2.COLOR_GRAY2RGB)
        m=np.where(prer>0)
        prer[m[0:2]]=[0,255,0]
        dst1 = cv2.addWeighted(prer,1,image2,0.5,0)
        self.canvas1.ax2.imshow(dst1, cmap='gray')
        self.canvas1.ax2.autoscale(enable=True, axis='x', tight=True)
        self.scl=5/reconstructed_image.shape[1]*1000
        self.den,self.dia=cal_den(self.reconstructed_image,self.scl)
        self.label_3.setText('Mean Density: {:.3f}  mm'.format(self.den))
        self.label_4.setText('Mean Diameter: {:.3f} um'.format(self.dia))
        #plt.axis('off')
        self.canvas1.draw()
    def plotdendia(self,predicted_patches):
        self.canvas2.ax1.clear()
        self.canvas2.ax2.clear()
        mydict1 = defaultdict(list)
        mydict2 = defaultdict(list)
        stat=[]
        for i in range(predicted_patches.shape[0]-1):
            scl=5/predicted_patches[i].shape[1]*1000
            if np.mean(predicted_patches[i])== 0:
                den=0
                dia=0
            else:
                a,b,c,d=Image.fromarray(predicted_patches[i]).getbbox()
                area=(c-a)*(d-b)*scl/1e6
                xx=label(predicted_patches[i], return_num=True, connectivity=2)
                if xx[1] != 0:
                    den=xx[1]/(area+0.1)
                    dia=2*np.mean(np.sqrt(np.unique(xx[0], return_counts=True)[1][1:]*scl/np.pi))
                    mydict1[den].append(den)
                    mydict2[dia].append(dia)
                    stat.append(np.array([den,dia]))
        d1=np.array(list(mydict1.keys())).astype(float)
        d2=np.array(list(mydict2.keys())).astype(float)
        d11=preprocessing.minmax_scale(d1, feature_range=(0, 1), axis=0, copy=True) 
        d22=preprocessing.minmax_scale(d2, feature_range=(0, 1), axis=0, copy=True) 
        x1=list(range(1,d1.shape[0]+1))
        x2=list(range(1,d2.shape[0]+1))
        fd11_sm = interp1d(x1, d11,kind='quadratic')
        x_new1 = np.linspace(np.min(x1), np.max(x1), 200)  
        self.canvas2.ax1.plot(x_new1,fd11_sm(x_new1))
        self.canvas2.ax1.autoscale(enable=True, axis='x', tight=True)
        self.canvas2.ax1.set_ylabel('Density (mm^2)')
        self.canvas2.ax1.set_xlabel('#Patches')
        fd22_sm = interp1d(x2, d22,kind='quadratic')
        x_new2 = np.linspace(np.min(x2), np.max(x2), 200)  
        self.canvas2.ax2.plot(x_new2,fd22_sm(x_new2))
        self.canvas2.ax2.set_ylabel('Diameter (um)')
        self.canvas2.ax2.set_xlabel('#Patches')
        self.canvas2.ax2.autoscale(enable=True, axis='x', tight=True) 
        self.canvas2.draw()
        self.stat=np.array(stat)
        df=pd.DataFrame(self.stat,columns=['Density_prediction','Diameter_prediction'])
        den_mean=np.mean(df['Density_prediction'])
        dia_mean=np.mean(df['Diameter_prediction'])
        self.label_3.setText('Mean Density: {:.3f}  mm'.format(den_mean))
        self.label_4.setText('Mean Diameter: {:.3f} um'.format(dia_mean))
        #self.checkBox(self.stat)        
    def checked(self):
        if self.checkBox.isChecked()==True:
           self.folder = QFileDialog.getExistingDirectory(None, "Select Directory")
           df=pd.DataFrame(self.stat,columns=['Density_prediction','Diameter_prediction'])
           ds=df.describe()
           ds.reset_index(inplace=True)
           pds=pd.DataFrame(np.pad(np.array(ds),((0,round(len(df))),(0,0)),'empty'),columns=['stat','Density_stat','Diameter_stat'])
           pd.merge(df, pds, left_index=True,right_index=True).to_csv(self.folder+r'\output_fromJPG_{}.csv'.format(datetime.now().strftime("%Y_%m_%d-%H_%M")),index=False)
        
      
    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.label.setText(_translate("MainWindow", "Kidney Segmentation"))
        self.pushButton.setText(_translate("MainWindow", "Load Image"))
        self.label_3.setText(_translate("MainWindow", "Density="))
        self.pushButton_2.setText(_translate("MainWindow", "Load Model"))
        self.label_4.setText(_translate("MainWindow", "Diameter="))
        self.checkBox.setText(_translate("MainWindow", "Save Stat"))
        self.menuMenu.setTitle(_translate("MainWindow", "Menu"))
        self.actionSave_images.setText(_translate("MainWindow", "Save images"))
        self.actionSave_plots.setText(_translate("MainWindow", "Save plots"))

    def closeEvent(self, event):
        reply = QtWidgets.QMessageBox.question(self, 'Message',"Do you reall want to leave?", QtWidgets.QMessageBox.Yes, QtWidgets.QMessageBox.No)

        if reply == QtWidgets.QMessageBox.Yes:
            event.accept() 
        else:
            event.ignore()
            
def cal_den(reconstructed_image,scl):
        a,b,c,d=Image.fromarray(reconstructed_image).getbbox()
        #Mean density
        area=(c-a)*(d-b)*scl/1e6
        xx=label(reconstructed_image, return_num=True, connectivity=2)
        if xx[1] != 0:
           den=xx[1]/(area+0.1)
           dia=2*np.mean(np.sqrt(np.unique(xx[0], return_counts=True)[1][1:]*scl/np.pi))
        return den,dia
def dice_coef(y_true, y_pred):
    y_truef=K.flatten(y_true)
    y_predf=K.flatten(y_pred)
    And=K.sum(y_truef* y_predf)
    return((2* And + 100) / (K.sum(y_truef) + K.sum(y_predf) + 100))

def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

def iou(y_true, y_pred):
    intersection = K.sum(y_true * y_pred)
    sum_ = K.sum(y_true + y_pred)
    jac = (intersection + 100) / (sum_ - intersection + 100)
    return jac

def jac_distance(y_true, y_pred):
    y_truef=K.flatten(y_true)
    y_predf=K.flatten(y_pred)

    return - iou(y_true, y_pred)
def conv_block(x, filter_size, size, dropout, batch_norm=False):
    
    conv = layers.Conv2D(size, (filter_size, filter_size), padding="same")(x)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    conv = layers.Activation("relu")(conv)

    conv = layers.Conv2D(size, (filter_size, filter_size), padding="same")(conv)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    conv = layers.Activation("relu")(conv)
    
    if dropout > 0:
        conv = layers.Dropout(dropout)(conv)

    return conv


def repeat_elem(tensor, rep):
    # lambda function to repeat Repeats the elements of a tensor along an axis
    #by a factor of rep.
    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape 
    #(None, 256,256,6), if specified axis=3 and rep=2.

     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),
                          arguments={'repnum': rep})(tensor)


def res_conv_block(x, filter_size, size, dropout, batch_norm=False):
    

    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    conv = layers.Activation('relu')(conv)
    
    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut
    if dropout > 0:
        conv = layers.Dropout(dropout)(conv)

    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)
    if batch_norm is True:
        shortcut = layers.BatchNormalization(axis=3)(shortcut)

    res_path = layers.add([shortcut, conv])
    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)
    return res_path

def gating_signal(input, out_size, batch_norm=False):
   
    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)
    if batch_norm:
        x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    return x

def attention_block(x, gating, inter_shape):
    shape_x = K.int_shape(x)
    shape_g = K.int_shape(gating)

# Getting the x signal to the same shape as the gating signal
    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16
    shape_theta_x = K.int_shape(theta_x)

# Getting the gating signal to the same number of filters as the inter_shape
    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)
    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),
                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),
                                 padding='same')(phi_g)  # 16

    concat_xg = layers.add([upsample_g, theta_x])
    act_xg = layers.Activation('relu')(concat_xg)
    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)
    sigmoid_xg = layers.Activation('sigmoid')(psi)
    shape_sigmoid = K.int_shape(sigmoid_xg)
    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32

    upsample_psi = repeat_elem(upsample_psi, shape_x[3])

    y = layers.multiply([upsample_psi, x])

    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)
    result_bn = layers.BatchNormalization()(result)
    return result_bn
def Attention_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):
    
    # network structure
    FILTER_NUM = 64 # number of basic filters for the first layer
    FILTER_SIZE = 3 # size of the convolutional filter
    UP_SAMP_SIZE = 2 # size of upsampling filters
    # input data
    # dimension of the image depth
    inputs = layers.Input(input_shape, dtype=tf.float32)
    axis = 3

    # Downsampling layers
    # DownRes 1, double residual convolution + pooling
    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)
    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)
    # DownRes 2
    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)
    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)
    # DownRes 3
    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)
    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)
    # DownRes 4
    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)
    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)
    # DownRes 5, convolution only
    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)

    # Upsampling layers
    # UpRes 6, attention gated concatenation + upsampling + double residual convolution
    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)
    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)
    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(conv_8)
    up_16 = layers.concatenate([up_16, att_16], axis=axis)
    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 7
    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)
    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)
    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_16)
    up_32 = layers.concatenate([up_32, att_32], axis=axis)
    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 8
    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)
    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)
    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_32)
    up_64 = layers.concatenate([up_64, att_64], axis=axis)
    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 9
    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)
    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)
    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_64)
    up_128 = layers.concatenate([up_128, att_128], axis=axis)
    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)

    # 1*1 convolutional layers
    
    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)
    conv_final = layers.BatchNormalization(axis=axis)(conv_final)
    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel

    # Model integration
    model = models.Model(inputs, conv_final, name="AttentionResUNet")
    return model
    
    
a = win32api.GetKeyState(0x01)
b = win32api.GetKeyState(0x02)

if __name__ == "__main__":
    app = QtWidgets.QApplication([])
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())    